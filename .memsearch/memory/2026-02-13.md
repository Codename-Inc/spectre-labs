
## Session 12:37


## Session 12:40

### 12:40
<!-- session:e5b9c4f5-4840-48ff-bf93-4b40c788016b turn:2262e3fb-c774-4026-83a6-435f3173e2db transcript:/Users/joe/.claude/projects/-Users-joe-Dev-spectre-labs/e5b9c4f5-4840-48ff-bf93-4b40c788016b.jsonl -->
- Explored antfarm project (TypeScript workflow framework, 864 stars): defines agents, steps, and state threading via YAML; uses SQLite + cron for async execution
- Antfarm enforces strict step contracts (input format, output expectations, acceptance criteria) and role-based access control (read-only agents can't write)
- Antfarm's `stories`, `fresh_session`, `verify_each` are first-class pipeline primitives for phase/batch execution; comparable to our phase-scoped validation design
- Antfarm auto-extracts variables from step output (KEY: value → {{key}}) vs. our manual hooks approach; hybrid could reduce boilerplate
- Antfarm uses escalate-to-human on repeated failures; our pipeline has GAPS_FOUND remediation loop but no human escalation
- Session context includes a resumable plan at /Users/joe/.claude/plans/rippling-wishing-forest.md for phase-scoped validation (phase_parser.py + hook updates + validate/code_review scoping)


## Session 12:41


## Session 12:41


## Session 16:44


## Session 16:44


## Session 16:44


## Session 16:46

### 16:46
<!-- session:5d65b5c4-2a99-45df-9e0f-af627de75be8 turn:8f646565-10c1-47d6-bacb-5bd170eb9a39 transcript:/Users/joe/.claude/projects/-Users-joe-Dev-spectre-labs/5d65b5c4-2a99-45df-9e0f-af627de75be8.jsonl -->
- **Current limitation**: Build loop requires strict markdown format (## Phase headers, task bullets) — fails silently or produces garbage on arbitrary input formats
- **Consumer product requirement**: Accept ANY tasks document format (plain text, bullet lists, different headers, mixed styles, etc.) and auto-normalize to internal representation
- **Proposed solution**: Input normalization layer that parses heterogeneous formats, constructs canonical work items (with phase/task structure), then feeds standardized output to existing pipeline
- **Key design questions before implementation**: (1) Should normalization happen once at startup or per-stage? (2) Do we preserve original document as reference or work only from normalized version? (3) How do we handle ambiguous cases (nested bullets, no clear phase boundaries)? (4) Should the normalized output be visible to user or stay internal? (5) Do we validate/warn on lossy conversions?
- **Architectural impact**: Adds a preprocessing stage before pipeline execution — could be a new `normalizer.py` module or integrated into loader.py
- **Product angle**: This unlocks "paste any work doc, Claude handles it" UX — huge friction reduction vs. "you must format it like this"
- **Risk consideration**: Over-aggressive normalization could discard important structure or context from original — need clear feedback loop so user sees what we parsed before execution starts

